{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j_UUTq-PT1k"
      },
      "source": [
        "# EE 467 Lab 1: ML Pipeline for Spam Detection\n",
        "\n",
        "In this lab, we will go through the process of a typical machine learning task, and apply it to a cyber-security problem. We will build a binary classifier that detects spam emails. Like previous lab, we will leave out some code for you to complete. Refer to API references and search on Google for usage of libraries and functions. Refer to previous labs and search on Google for usage of libraries and functions, and ask TA or Instructor if you don't really have a clue.\n",
        "\n",
        "Before working on the code, we will need to install `NLTK` and `scikit-learn` for this lab:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Zjx8guPT1m",
        "outputId": "f97ff580-1146-4711-e466-9e602ea9e7a0",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /home/tdokkad/anaconda3-new/lib/python3.12/site-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /home/tdokkad/anaconda3-new/lib/python3.12/site-packages (1.6.1)\n",
            "Requirement already satisfied: click in /home/tdokkad/anaconda3-new/lib/python3.12/site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /home/tdokkad/anaconda3-new/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/tdokkad/anaconda3-new/lib/python3.12/site-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /home/tdokkad/anaconda3-new/lib/python3.12/site-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /home/tdokkad/anaconda3-new/lib/python3.12/site-packages (from scikit-learn) (2.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /home/tdokkad/anaconda3-new/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/tdokkad/anaconda3-new/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install nltk scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaEWTjp0PT1n"
      },
      "source": [
        "And ensure the dataset is extracted from the archive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9is6J72DPT1n",
        "outputId": "3e74a2b2-74b9-4e49-9a31-ae39d5e565cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.macl'\n"
          ]
        }
      ],
      "source": [
        "# Extract data\n",
        "!tar -xf emails.tar.xz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRVyTUb3PT1n"
      },
      "source": [
        "Then import the libraries we will use here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGr3vz7gPT1n",
        "outputId": "fb868e66-706b-4c9b-92f3-f1d34f919aba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/tdokkad/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# IMPORT REQUIRED LIBRARIES\n",
        "# =============================================================================\n",
        "# string   - Python's built-in module for string operations (punctuation list)\n",
        "# numpy    - Numerical computing (we use 'np' as the standard alias)\n",
        "# pandas   - Data manipulation and analysis (we use 'pd' as the standard alias)\n",
        "# nltk     - Natural Language Toolkit for text processing\n",
        "# =============================================================================\n",
        "\n",
        "import string\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# NLTK (Natural Language Toolkit) - the most popular Python library for NLP\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stop words (common words like \"the\", \"a\", \"is\" that add no meaning)\n",
        "# These need to be downloaded once before use\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elnpAo5yPT1o"
      },
      "source": [
        "## Pre-processing\n",
        "\n",
        "All machine learning tasks begin with the **pre-processing** step, during which we load the dataset into memory and \"clean\" the data so that they are suitable for subsequent steps. For spam email detection task, here we will load all emails into the memory, tokenize each email into a list of words and then remove words that are useless for analysis.\n",
        "\n",
        "All emails are stored in `emails.csv` under the same directory as this notebook. Feel free to open the file, take a look and get familiar with the format of the email dataset, then go back here to load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH2gqphfPT1o",
        "outputId": "27958fe5-c749-45a5-abd5-099951240dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                text  spam\n",
            "0  Subject: naturally irresistible your corporate...     1\n",
            "1  Subject: the stock trading gunslinger  fanny i...     1\n",
            "2  Subject: unbelievable new homes made easy  im ...     1\n",
            "3  Subject: 4 color printing special  request add...     1\n",
            "4  Subject: do not have money , get software cds ...     1 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# LOADING THE DATASET\n",
        "# =============================================================================\n",
        "# pd.read_csv() reads a CSV file and returns a DataFrame\n",
        "# A DataFrame is like a spreadsheet - rows are samples, columns are features\n",
        "# =============================================================================\n",
        "\n",
        "# Load email dataset into a DataFrame\n",
        "df = pd.read_csv(\"emails.csv\")\n",
        "\n",
        "# Preview first 5 rows\n",
        "print(df.head(5), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOZgxL_vPT1o",
        "outputId": "fc2e59d8-2554-4777-c1f4-2b2e7e2c331b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (5728, 2)\n",
            "Columns: Index(['text', 'spam'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Check dataset size and columns\n",
        "print(\"Shape:\", df.shape)      # (rows, columns)\n",
        "print(\"Columns:\", df.columns)  # 'text' = email, 'spam' = label (1=spam, 0=ham)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FxaHyRLDPT1o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "De-duplicated shape: (5695, 2)\n"
          ]
        }
      ],
      "source": [
        "## [ TODO 1 ] Remove duplicate rows from the DataFrame\n",
        "#\n",
        "# Hint: DataFrames have a method for removing duplicates in-place.\n",
        "#       After removing, print the shape to verify - expect fewer rows.\n",
        "#       Look up: pandas DataFrame drop_duplicates documentation\n",
        "#\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "print(\"De-duplicated shape:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WqVsI-LKPT1p"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "text    0\n",
              "spam    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Number of missing (NAN, NaN, na) data for each column\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtoegYUOPT1p"
      },
      "source": [
        "After loading the email dataset into memory, we will need to remove punctuations and stop words from these emails. Stop words are common, useless words that should be ignored in analysis (such as a, an, the, ...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xxXxXArePT1p"
      },
      "outputs": [],
      "source": [
        "# Text tokenizer: removes punctuation and stop words\n",
        "def process_text(text):\n",
        "    \"\"\"Convert email text to list of meaningful words.\"\"\"\n",
        "\n",
        "    # Remove punctuation (!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~)\n",
        "    nopunc = [char for char in text if char not in string.punctuation]\n",
        "    nopunc = ''.join(nopunc)\n",
        "\n",
        "    # Remove stop words (\"the\", \"a\", \"is\", etc.) - case insensitive\n",
        "    clean_words = [word for word in nopunc.split()\n",
        "                   if word.lower() not in stopwords.words('english')]\n",
        "\n",
        "    return clean_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "EWBnGCsePT1p",
        "outputId": "7d05f7f0-5011-4bcb-94b3-ad1773771351"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [Subject, naturally, irresistible, corporate, ...\n",
              "1    [Subject, stock, trading, gunslinger, fanny, m...\n",
              "2    [Subject, unbelievable, new, homes, made, easy...\n",
              "3    [Subject, 4, color, printing, special, request...\n",
              "4    [Subject, money, get, software, cds, software,...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview the result of tokenization\n",
        "df['text'].head().apply(process_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh4kfn-6PT1p"
      },
      "source": [
        "## Feature Extraction\n",
        "\n",
        "We have obtained semi-structured tokenized email texts in the pre-processing step; however, machine learning algorithms usually operate on fully-structured numerical features. Hence, we need to find a way to convert the email texts to numeric vectors. This process is called **feature extraction**, and is necessary in data mining and analysis tasks where input data is semi-structured or even unstructured. In the following part we will make use of `scikit-learn`, which is a library for classic machine learning and feature extraction.\n",
        "\n",
        "We will use **token count features** to represent the characteristics of each email. This turns a piece of text into a vector, each dimension of which contains the number of occurance of a particular word. In practice, we process many texts at once and end up getting a token count matrix. Below is simple demo on a toy dataset with only two emails:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SR5lKkFAPT1p"
      },
      "outputs": [],
      "source": [
        "# DEMO: Bag-of-Words converts text → word count vectors\n",
        "\n",
        "message4 = 'hello world hello hello world play'\n",
        "message5 = 'test test test test one hello'\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# CountVectorizer: text → matrix where each column = a word, values = counts\n",
        "cv = CountVectorizer(analyzer=process_text)\n",
        "bow4 = cv.fit_transform([[message4], [message5]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUj5D0SBPT1p",
        "outputId": "080b5163-3fae-4e3e-f7d8-3cddb7c8057d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['hello' 'one' 'play' 'test' 'world'] \n",
            "\n",
            "[[3 0 1 0 2]\n",
            " [1 1 0 4 0]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Vocabulary = unique words (these become column names)\n",
        "print(cv.get_feature_names_out(), \"\\n\")\n",
        "\n",
        "# Count matrix: rows = documents, columns = word counts\n",
        "print(bow4.toarray(), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8IXHIprPT1p",
        "outputId": "a14d9c95-e1f4-4eb8-9513-4989a275b74b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 6 stored elements and shape (2, 5)>\n",
            "  Coords\tValues\n",
            "  (0, 0)\t3\n",
            "  (0, 4)\t2\n",
            "  (0, 2)\t1\n",
            "  (1, 0)\t1\n",
            "  (1, 3)\t4\n",
            "  (1, 1)\t1 <class 'scipy.sparse._csr.csr_matrix'> \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Sparse format: only stores non-zero values (saves memory)\n",
        "print(bow4, type(bow4), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgfOHsqUPT1p"
      },
      "source": [
        "Now let's compute and store token count matrix for real data:\n",
        "\n",
        "## Create bag-of-words matrix for all emails\n",
        "\n",
        "In this step, you will convert the email **text content** into a **Bag-of-Words (BoW)** representation using `CountVectorizer`.\n",
        "\n",
        "✅ **Important note:**  \n",
        "In the in-class demo, we used `CountVectorizer(analyzer=process_text)`, where `process_text` performs custom text processing.  \n",
        "That approach can be **slow** and may produce **many printed outputs** because the custom analyzer shows intermediate processing steps.\n",
        "\n",
        "For this lab, we will use a simpler and faster approach by letting `CountVectorizer` handle the tokenization internally, and we will enable English stop-word removal using:\n",
        "\n",
        "- `stop_words=\"english\"`\n",
        "\n",
        "➡️ Your task: apply `CountVectorizer(stop_words=\"english\")` on the `text` column and store the result in `messages_bow` as a **sparse matrix**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9osgK5BsPT1p"
      },
      "outputs": [],
      "source": [
        "## [ TODO 2 ] Create bag-of-words matrix for all emails\n",
        "#\n",
        "# Hint: Use CountVectorizer with stop-word removal to fit and transform email text\n",
        "#       into a Bag-of-Words matrix.\n",
        "#       Apply it to the 'text' column of df. Store result in 'messages_bow'.\n",
        "#       Note: Keep it as sparse matrix (don't convert to array).\n",
        "#\n",
        "cv = CountVectorizer(stop_words=\"english\")\n",
        "messages_bow = cv.fit_transform(df['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08AAR1-dPT1q"
      },
      "source": [
        "## Training\n",
        "\n",
        "Now that we have loaded and pre-processed the email dataset, it's time to **train** a classifier model that does the job. First, we will split the email dataset into a 80% **training set** and a 20% **test set**. Each set will contain sample features as well as corresponding labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KWKaFDkbPT1q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into 80% training (X_train & y_train)\n",
        "# and 20% testing (X_test & y_test) data sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(messages_bow, df['spam'], test_size = 0.20, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-PwjtkEPT1q"
      },
      "source": [
        "Then, we train a **logistic regression** classifier on the training set. We determine the class of the sample through its probability which is computed from the following formula:\n",
        "\n",
        "$$\n",
        "P(Y = 1|X = x) = \\frac{e^{\\mathbf{X}^T \\mathbf{b}}}{(1+e^{\\mathbf{X}^T \\mathbf{b}})} \\\\\n",
        "P(Y = 0|X = x) = 1 - P(Y = 1|X = x)\n",
        "$$\n",
        "\n",
        "Where $\\mathbf{b}$ is a trainable vector. During training, we will try to maximize the **cross entropy loss** by performing **stochastic gradient descent** on parameter $\\mathbf{b}$:\n",
        "\n",
        "$$\n",
        "l_{CE} = -(y \\log P(Y = 1|X = x) + (1 - y) \\log P(Y = 0|X = x))\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2qJIq3TYPT1q",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "## [ TODO 3 ] Create and train a logistic regression classifier\n",
        "#\n",
        "# Hint: Instantiate LogisticRegression (use random_state=0 for reproducibility).\n",
        "#       Then call the appropriate method to train on X_train and y_train.\n",
        "#       Store the model in a variable called 'classifier'.\n",
        "#\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p45HPPxiPT1q"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Finally, we need to determine how good our classification model is. This is known as **evaluation**. We will use our trained model to make predictions for both training and testing data, and calculate various metrics with the predictions and actual labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YrwgOf3CPT1q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training prediction:\n",
            " [0 0 0 ... 0 0 0] \n",
            "\n",
            "Training actual:\n",
            " [0 0 0 ... 0 0 0] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print predictions on training data\n",
        "# `predict` function compute model predictions from input data\n",
        "print(\"Training prediction:\\n\", classifier.predict(X_train), \"\\n\")\n",
        "\n",
        "# Print the actual labels\n",
        "print(\"Training actual:\\n\", y_train.values, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03v6kf7KPT1q"
      },
      "source": [
        "There are a number of useful metrics for evaluation of binary classifiers, available through `classification_report`, `confusion_matrix` and `accuracy_score` functions:\n",
        "\n",
        "* **Confusion Matrix**: a matrix that indicates how many samples are correctly or incorrectly classified. The cell at $i$-th row and $j$-th column represents how many samples that belong to $i$-th class and are predicted as $j$-th class. For binary classification, the confusion matrix has only two columns and two rows:\n",
        "\n",
        "|Class|True               |False              |\n",
        "|-----|-------------------|-------------------|\n",
        "|True |True Positive (TP) |False Negative (FN)|\n",
        "|False|False Positive (FP)|True Negative (TN) |\n",
        "\n",
        "* **Accuracy**: proportion of samples that are correctly classified.\n",
        "\n",
        "$$\n",
        "Accuracy = \\frac{TP+TN}{TP+FP+TN+FN}\n",
        "$$\n",
        "\n",
        "* **Precision**: of all positive predictions, how many of them are actually correct?\n",
        "\n",
        "$$\n",
        "Precision = \\frac{TP}{TP+FP}\n",
        "$$\n",
        "\n",
        "* **Recall**: of all actually positive samples, how many of them are predicted correctly?\n",
        "\n",
        "$$\n",
        "Recall = \\frac{TP}{TP+FN}\n",
        "$$\n",
        "\n",
        "* **F1 Score**: the harmonic mean of precision and recall.\n",
        "\n",
        "$$\n",
        "F1 = \\frac{2 \\cdot Precision \\cdot Recall}{Precision + Recall}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjGVNZnoPT1q"
      },
      "source": [
        "We first calculates and prints various metrics for training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_RRmxZqjPT1q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3457\n",
            "           1       1.00      1.00      1.00      1099\n",
            "\n",
            "    accuracy                           1.00      4556\n",
            "   macro avg       1.00      1.00      1.00      4556\n",
            "weighted avg       1.00      1.00      1.00      4556\n",
            "\n",
            "Confusion Matrix: \n",
            " [[3457    0]\n",
            " [   0 1099]] \n",
            "\n",
            "Accuracy:  1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Predict and evaluate on training data\n",
        "pred = classifier.predict(X_train)\n",
        "\n",
        "# `classification_report` outputs classification metrics\n",
        "# such as precision, recall and F1 score\n",
        "print(classification_report(y_train, pred))\n",
        "\n",
        "# `confusion_matrix` outputs how many samples are correctly or incorrectly classified\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_train, pred), \"\\n\")\n",
        "\n",
        "# `accuracy` computes classification accuracy\n",
        "print('Accuracy: ', accuracy_score(y_train, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os791MNHPT1q"
      },
      "source": [
        "We now calculates and prints the same metrics for testing data. This measures the ability of the classification model to generalize to similar yet unknown data. The less difference in training and testing data, the better the model is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "df8bCez2PT1q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test prediction: [1 0 0 ... 0 0 0] \n",
            "\n",
            "Test actual:     [0 0 0 ... 0 0 0] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "## [ TODO 4 ] Print test predictions and actual labels\n",
        "#\n",
        "# Hint: Use the trained classifier to predict on X_test.\n",
        "#       Print both the predictions and y_test values side by side.\n",
        "#       Follow the same pattern used for training data in Cell 25.\n",
        "#\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "print(\"Test prediction:\", y_pred, \"\\n\")\n",
        "print(\"Test actual:    \", y_train.values, \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rK0oRo-jPT1q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       870\n",
            "           1       0.98      0.98      0.98       269\n",
            "\n",
            "    accuracy                           0.99      1139\n",
            "   macro avg       0.99      0.99      0.99      1139\n",
            "weighted avg       0.99      0.99      0.99      1139\n",
            "\n",
            "Confusion Matrix: \n",
            " [[865   5]\n",
            " [  5 264]] \n",
            "\n",
            "Accuracy:  0.9912203687445127\n"
          ]
        }
      ],
      "source": [
        "## [ TODO 5 ] Evaluate classifier on test data\n",
        "#\n",
        "# Hint: Follow the same evaluation pattern used for training data previously.\n",
        "#       Use the three imported metrics functions on X_test/y_test.\n",
        "#       Expected accuracy should be around 98-99%.\n",
        "#\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred), \"\\n\")\n",
        "print('Accuracy: ', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od8bz8ieTNui"
      },
      "source": [
        "## Discussion Question: Why Bag-of-Words (BoW) Still Works (and its Limitations)\n",
        "\n",
        "In this lab, we used **Bag-of-Words (BoW)** to convert email text into numerical features that a machine learning model can understand.\n",
        "\n",
        "### A common concern with BoW\n",
        "In the in-class discussion, we learned that some words appear in **many** documents (examples: *“the”*, *“and”*, *“hello”*, *“thanks”*). These very frequent words can cause two issues:\n",
        "\n",
        "1. **They do not help distinguish spam vs. ham**  \n",
        "   If a word appears in almost every email, it does not provide useful information for classification.\n",
        "\n",
        "2. **Different emails can look similar in feature space**  \n",
        "   Two different messages may share many common words, which can lead to **similar BoW representations**, even if their meaning is different.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Your Task (Short Answer)\n",
        "Even with the limitations above, BoW often performs surprisingly well for spam detection.\n",
        "\n",
        "**Why does the Bag-of-Words method still work well in this lab?**  \n",
        "Write a **short explanation** (2–4 sentences) and include **at least one clear reason** supported by what you observe in the dataset or model behavior.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While many words are generic or may be shared between spam and benign emails, certain vocabulary is much more common in spam emails. Some examples from the preview of the dataset are 'irresistable', 'unbelievable', 'stock' + 'trading', &c. While ham emails may use some of these words, they are less likely to use many of them unless the message is particularly long (in which case a lot of 'innocent' words will be used as well). There may also be terminology or lexicon used in, for example, legitimate emails about stock trading that are less likely to show up in poorly constructed attention-grabbing spam emails, which can help the model recognize ham emails while flagging other emails that use the 'suspicious' keywords."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zltAtnu8PT1q"
      },
      "source": [
        "## References\n",
        "1. https://github.com/randerson112358/Python/blob/master/Email_Spam_Detection/Email_Spam_Detection.ipynb\n",
        "2. https://stackoverflow.com/questions/27488446/how-do-i-get-word-frequency-in-a-corpus-using-scikit-learn-countvectorizer"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
